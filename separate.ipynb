{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Directory: Dataset/Bangla/Dataset/Train\n",
      "Checked 12000 images in total.\n",
      "Removed 0 unreadable images.\n",
      "Removed 0 non-image files.\n",
      "Total number of images: 12000\n",
      "Total number of labels: 50\n",
      "\n",
      "Directory: Dataset/Bangla/Dataset/Test\n",
      "Checked 3000 images in total.\n",
      "Removed 0 unreadable images.\n",
      "Removed 0 non-image files.\n",
      "Total number of images: 3000\n",
      "Total number of labels: 50\n",
      "\n",
      "Directory: Dataset/English/data/training_data\n",
      "Checked 20628 images in total.\n",
      "Removed 0 unreadable images.\n",
      "Removed 0 non-image files.\n",
      "Total number of images: 20628\n",
      "Total number of labels: 36\n",
      "\n",
      "Directory: Dataset/English/data/testing_data\n",
      "Checked 1008 images in total.\n",
      "Removed 0 unreadable images.\n",
      "Removed 0 non-image files.\n",
      "Total number of images: 1008\n",
      "Total number of labels: 36\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from preprocess import OCRDataset  # Import from preprocess.py\n",
    "import os\n",
    "from model import OCRModel\n",
    "from dataload import bangla_load, english_load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bangla_train_loader, bangla_val_loader, bangla_test_loader, bangla_num_classes = bangla_load\n",
    "english_train_loader, english_val_loader, english_test_loader, english_num_classes = english_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OCRTrainer:\n",
    "    def __init__(self, model, train_loader, val_loader, test_loader, lr=0.001):\n",
    "        \n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.lr = lr\n",
    "\n",
    "        # Determine device\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # Assign model and move it to the device\n",
    "        self.model = model.to(self.device)\n",
    "\n",
    "        # Define loss and optimizer\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "\n",
    "    def train_and_validate(self, epochs=10):\n",
    "        \n",
    "        history = {\n",
    "            \"train_loss\": [],\n",
    "            \"train_accuracy\": [],\n",
    "            \"val_loss\": [],\n",
    "            \"val_accuracy\": []\n",
    "        }\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            # Training\n",
    "            self.model.train()\n",
    "            running_loss = 0.0\n",
    "            correct_train = 0\n",
    "            total_train = 0\n",
    "            for images, labels in self.train_loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(images)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "\n",
    "                # Training accuracy\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total_train += labels.size(0)\n",
    "                correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "            train_loss = running_loss / len(self.train_loader)\n",
    "            train_accuracy = 100 * correct_train / total_train\n",
    "\n",
    "            # Validation\n",
    "            self.model.eval()\n",
    "            val_loss = 0.0\n",
    "            correct_val = 0\n",
    "            total_val = 0\n",
    "            with torch.no_grad():\n",
    "                for images, labels in self.val_loader:\n",
    "                    images, labels = images.to(self.device), labels.to(self.device)\n",
    "                    outputs = self.model(images)\n",
    "                    loss = self.criterion(outputs, labels)\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "                    # Validation accuracy\n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    total_val += labels.size(0)\n",
    "                    correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "            val_loss = val_loss / len(self.val_loader)\n",
    "            val_accuracy = 100 * correct_val / total_val\n",
    "\n",
    "            # Append metrics to history\n",
    "            history[\"train_loss\"].append(train_loss)\n",
    "            history[\"train_accuracy\"].append(train_accuracy)\n",
    "            history[\"val_loss\"].append(val_loss)\n",
    "            history[\"val_accuracy\"].append(val_accuracy)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, \"\n",
    "                  f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "        return history\n",
    "\n",
    "    def test(self):\n",
    "        \n",
    "        self.model.eval()\n",
    "        test_loss = 0.0\n",
    "        correct_test = 0\n",
    "        total_test = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in self.test_loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                outputs = self.model(images)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                test_loss += loss.item()\n",
    "\n",
    "                # Test accuracy\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total_test += labels.size(0)\n",
    "                correct_test += (predicted == labels).sum().item()\n",
    "\n",
    "        test_loss = test_loss / len(self.test_loader)\n",
    "        test_accuracy = 100 * correct_test / total_test\n",
    "        print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "        return test_loss, test_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 3.0611, Train Accuracy: 31.41%, Val Loss: 2.0796, Val Accuracy: 57.67%\n",
      "Epoch 2: Train Loss: 1.5686, Train Accuracy: 70.19%, Val Loss: 1.1572, Val Accuracy: 79.83%\n",
      "Epoch 3: Train Loss: 0.9353, Train Accuracy: 83.36%, Val Loss: 0.7822, Val Accuracy: 85.33%\n",
      "Epoch 4: Train Loss: 0.6321, Train Accuracy: 88.57%, Val Loss: 0.5800, Val Accuracy: 88.00%\n",
      "Epoch 5: Train Loss: 0.4519, Train Accuracy: 92.18%, Val Loss: 0.4766, Val Accuracy: 89.50%\n",
      "Epoch 6: Train Loss: 0.3287, Train Accuracy: 94.59%, Val Loss: 0.3845, Val Accuracy: 92.83%\n",
      "Epoch 7: Train Loss: 0.2443, Train Accuracy: 96.28%, Val Loss: 0.3355, Val Accuracy: 93.50%\n",
      "Epoch 8: Train Loss: 0.1813, Train Accuracy: 97.49%, Val Loss: 0.3028, Val Accuracy: 93.17%\n",
      "Epoch 9: Train Loss: 0.1377, Train Accuracy: 98.48%, Val Loss: 0.2815, Val Accuracy: 94.00%\n",
      "Epoch 10: Train Loss: 0.1015, Train Accuracy: 99.00%, Val Loss: 0.2534, Val Accuracy: 94.00%\n",
      "Test Loss: 0.2951, Test Accuracy: 91.90%\n",
      "Epoch 1: Train Loss: 1.2169, Train Accuracy: 80.42%, Val Loss: 0.3478, Val Accuracy: 93.12%\n",
      "Epoch 2: Train Loss: 0.2160, Train Accuracy: 95.49%, Val Loss: 0.2088, Val Accuracy: 94.57%\n",
      "Epoch 3: Train Loss: 0.1404, Train Accuracy: 96.43%, Val Loss: 0.1744, Val Accuracy: 95.74%\n",
      "Epoch 4: Train Loss: 0.1049, Train Accuracy: 97.17%, Val Loss: 0.1449, Val Accuracy: 96.22%\n",
      "Epoch 5: Train Loss: 0.0847, Train Accuracy: 97.58%, Val Loss: 0.1399, Val Accuracy: 95.83%\n",
      "Epoch 6: Train Loss: 0.0721, Train Accuracy: 97.83%, Val Loss: 0.1388, Val Accuracy: 96.71%\n",
      "Epoch 7: Train Loss: 0.0617, Train Accuracy: 98.09%, Val Loss: 0.1294, Val Accuracy: 96.80%\n",
      "Epoch 8: Train Loss: 0.0497, Train Accuracy: 98.39%, Val Loss: 0.1242, Val Accuracy: 96.71%\n",
      "Epoch 9: Train Loss: 0.0454, Train Accuracy: 98.51%, Val Loss: 0.1161, Val Accuracy: 96.71%\n",
      "Epoch 10: Train Loss: 0.0402, Train Accuracy: 98.58%, Val Loss: 0.1188, Val Accuracy: 96.71%\n",
      "Test Loss: 0.0394, Test Accuracy: 98.02%\n"
     ]
    }
   ],
   "source": [
    "# Common data\n",
    "lr = 0.0001\n",
    "epochs = 10\n",
    "\n",
    "# Initialize the model\n",
    "bangla_model = OCRModel(bangla_num_classes)\n",
    "\n",
    "# Initialize the trainer\n",
    "bangla_trainer = OCRTrainer(bangla_model, bangla_train_loader, bangla_val_loader, bangla_test_loader, lr=lr)\n",
    "\n",
    "# Train and validate\n",
    "bangla_history = bangla_trainer.train_and_validate(epochs=epochs)\n",
    "\n",
    "# Test\n",
    "test_loss, test_accuracy = bangla_trainer.test()\n",
    "\n",
    "# Initialize the model\n",
    "english_model = OCRModel(english_num_classes)\n",
    "\n",
    "# Initialize the trainer\n",
    "english_trainer = OCRTrainer(english_model, english_train_loader, english_val_loader, english_test_loader, lr=lr)\n",
    "\n",
    "\n",
    "# Train and validate\n",
    "english_history = english_trainer.train_and_validate(epochs=epochs)\n",
    "\n",
    "# Test\n",
    "test_loss, test_accuracy = english_trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "\n",
    "class Evaluator:\n",
    "    def __init__(self, model, test_loader, num_classes, output_dir=\"evaluation_outputs\"):\n",
    "        \"\"\"\n",
    "        Initializes the evaluator.\n",
    "\n",
    "        Args:\n",
    "            model (torch.nn.Module): Trained model to evaluate.\n",
    "            test_loader (DataLoader): DataLoader for the test dataset.\n",
    "            num_classes (int): Number of classes in the dataset.\n",
    "            output_dir (str): Directory to save evaluation plots and metrics.\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.test_loader = test_loader\n",
    "        self.num_classes = num_classes\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.output_dir = output_dir\n",
    "\n",
    "        # Create output directory if it doesn't exist\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    def evaluate_and_save(self):\n",
    "        \"\"\"\n",
    "        Evaluates the model on test data and saves visualizations and metrics to disk.\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        all_images = []\n",
    "        all_labels = []\n",
    "        all_predictions = []\n",
    "        all_probabilities = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in self.test_loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                outputs = self.model(images)\n",
    "                probabilities = torch.softmax(outputs, dim=1)\n",
    "                _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "                # Collect all images, labels, and predictions\n",
    "                all_images.extend(images.cpu())  # Collect all test images\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_predictions.extend(predictions.cpu().numpy())\n",
    "                all_probabilities.extend(probabilities.cpu().numpy())\n",
    "\n",
    "        # Convert collected data to NumPy arrays\n",
    "        all_labels = np.array(all_labels)\n",
    "        all_predictions = np.array(all_predictions)\n",
    "        all_probabilities = np.array(all_probabilities)\n",
    "\n",
    "        # Save sample predictions\n",
    "        self._save_sample_predictions(all_images, all_labels, all_predictions)\n",
    "\n",
    "        # Save confusion matrix\n",
    "        self._save_confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "        # Save classification report\n",
    "        self._save_classification_report(all_labels, all_predictions)\n",
    "\n",
    "        # Save ROC curve\n",
    "        self._save_roc_curve(all_labels, all_probabilities)\n",
    "\n",
    "    def _save_sample_predictions(self, images, labels, predictions):\n",
    "        \"\"\"\n",
    "        Randomly selects test images until there are images of 5 unique labels \n",
    "        and saves them along with their predictions and true labels to a file.\n",
    "        \"\"\"\n",
    "        max_samples = 5  # Limit the number of unique labels\n",
    "        unique_labels = {}\n",
    "        selected_indices = []\n",
    "        total_samples = len(labels)\n",
    "\n",
    "        # Randomly shuffle indices\n",
    "        indices = list(range(total_samples))\n",
    "        random.shuffle(indices)\n",
    "\n",
    "        # Select images with unique labels\n",
    "        for idx in indices:\n",
    "            label = labels[idx]\n",
    "            if label not in unique_labels:\n",
    "                unique_labels[label] = True\n",
    "                selected_indices.append(idx)\n",
    "                if len(unique_labels) == max_samples:\n",
    "                    break\n",
    "\n",
    "        # Plot and save the selected samples\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        for i, idx in enumerate(selected_indices):\n",
    "            plt.subplot(1, len(selected_indices), i + 1)\n",
    "            plt.imshow(images[idx].squeeze(), cmap='gray')\n",
    "            plt.title(f\"True: {labels[idx]}\\nPred: {predictions[idx]}\")\n",
    "            plt.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        file_path = os.path.join(self.output_dir, \"sample_predictions.png\")\n",
    "        plt.savefig(file_path)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def _save_confusion_matrix(self, labels, predictions):\n",
    "        \"\"\"\n",
    "        Saves the confusion matrix to a file.\n",
    "        \"\"\"\n",
    "        cm = confusion_matrix(labels, predictions)\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=True, yticklabels=True)\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        file_path = os.path.join(self.output_dir, \"confusion_matrix.png\")\n",
    "        plt.savefig(file_path)\n",
    "        plt.close()\n",
    "\n",
    "    def _save_classification_report(self, labels, predictions):\n",
    "        \"\"\"\n",
    "        Saves the classification report to a text file.\n",
    "        \"\"\"\n",
    "        report = classification_report(labels, predictions)\n",
    "        file_path = os.path.join(self.output_dir, \"classification_report.txt\")\n",
    "        with open(file_path, \"w\") as f:\n",
    "            f.write(report)\n",
    "\n",
    "    def _save_roc_curve(self, labels, probabilities):\n",
    "        # Binarize labels for multi-class ROC calculation\n",
    "        labels_binarized = label_binarize(labels, classes=range(self.num_classes))\n",
    "        fpr, tpr, _ = roc_curve(labels_binarized.ravel(), probabilities.ravel())\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        # Plot the ROC curve\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.plot(fpr, tpr, label=f\"Combined Classes (AUC = {roc_auc:.2f})\")\n",
    "        plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line\n",
    "        plt.title(\"ROC Curve (All Classes)\")\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        file_path = os.path.join(self.output_dir, \"roc_curve.png\")\n",
    "        plt.savefig(file_path)\n",
    "        plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Function to plot and save accuracy and loss graphs\n",
    "def save_training_plots(history, output_dir, model_name):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Plot Train vs Validation Accuracy\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history['train_accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title(f\"{model_name} Model Accuracy\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    accuracy_plot_path = os.path.join(output_dir, f\"{model_name.lower()}_accuracy.png\")\n",
    "    plt.savefig(accuracy_plot_path)\n",
    "    plt.close()\n",
    "\n",
    "    # Plot Train vs Validation Loss\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history['train_loss'], label='Train Loss')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.title(f\"{model_name} Model Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    loss_plot_path = os.path.join(output_dir, f\"{model_name.lower()}_loss.png\")\n",
    "    plt.savefig(loss_plot_path)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate and save outputs\n",
    "bangla_evaluator = Evaluator(bangla_model, bangla_test_loader, bangla_num_classes, output_dir=\"bangla_evaluation_outputs\")\n",
    "bangla_evaluator.evaluate_and_save()\n",
    "save_training_plots(bangla_history, output_dir=\"bangla_evaluation_outputs\", model_name=\"Bangla\")\n",
    "\n",
    "english_evaluator = Evaluator(english_model, english_test_loader, english_num_classes, output_dir=\"english_evaluation_outputs\")\n",
    "english_evaluator.evaluate_and_save()\n",
    "save_training_plots(english_history, output_dir=\"english_evaluation_outputs\", model_name=\"English\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bangla model saved to saved_models/bangla_model.pth\n",
      "English model saved to saved_models/english_model.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Directory to save models\n",
    "model_save_dir = \"saved_models\"\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "# Save Bangla model\n",
    "bangla_model_path = os.path.join(model_save_dir, \"bangla_model.pth\")\n",
    "torch.save({\n",
    "    'model_state_dict': bangla_model.state_dict(),\n",
    "    'optimizer_state_dict': bangla_trainer.optimizer.state_dict(),\n",
    "    'history': bangla_history\n",
    "}, bangla_model_path)\n",
    "print(f\"Bangla model saved to {bangla_model_path}\")\n",
    "\n",
    "# Save English model\n",
    "english_model_path = os.path.join(model_save_dir, \"english_model.pth\")\n",
    "torch.save({\n",
    "    'model_state_dict': english_model.state_dict(),\n",
    "    'optimizer_state_dict': english_trainer.optimizer.state_dict(),\n",
    "    'history': english_history\n",
    "}, english_model_path)\n",
    "print(f\"English model saved to {english_model_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Directory: Dataset/Bangla/Dataset/Train\n",
      "Checked 12000 images in total.\n",
      "Removed 0 unreadable images.\n",
      "Removed 0 non-image files.\n",
      "Total number of images: 12000\n",
      "Total number of labels: 50\n",
      "\n",
      "Directory: Dataset/Bangla/Dataset/Test\n",
      "Checked 3000 images in total.\n",
      "Removed 0 unreadable images.\n",
      "Removed 0 non-image files.\n",
      "Total number of images: 3000\n",
      "Total number of labels: 50\n",
      "\n",
      "Directory: Dataset/English/data/training_data\n",
      "Checked 20628 images in total.\n",
      "Removed 0 unreadable images.\n",
      "Removed 0 non-image files.\n",
      "Total number of images: 20628\n",
      "Total number of labels: 36\n",
      "\n",
      "Directory: Dataset/English/data/testing_data\n",
      "Checked 1008 images in total.\n",
      "Removed 0 unreadable images.\n",
      "Removed 0 non-image files.\n",
      "Total number of images: 1008\n",
      "Total number of labels: 36\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from preprocess import preprocess_image  # Import from preprocess.py\n",
    "from model import OCRModel  # Import from separate.py\n",
    "from dataload import bangla_load, english_load\n",
    "\n",
    "# Load Bangla and English data loaders\n",
    "bangla_train_loader, bangla_val_loader, bangla_test_loader, bangla_num_classes = bangla_load\n",
    "english_train_loader, english_val_loader, english_test_loader, english_num_classes = english_load\n",
    "\n",
    "# Load pre-trained models with weights_only=True\n",
    "bangla_model = OCRModel(bangla_num_classes)\n",
    "english_model = OCRModel(english_num_classes)\n",
    "bangla_model.load_state_dict(torch.load(\"saved_models/bangla_model.pth\", weights_only=True)['model_state_dict'])\n",
    "english_model.load_state_dict(torch.load(\"saved_models/english_model.pth\", weights_only=True)['model_state_dict'])\n",
    "\n",
    "# Combined model\n",
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, bangla_model, english_model, combined_classes):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        self.bangla_feature_extractor = nn.Sequential(*list(bangla_model.children())[:-2])  # Up to LSTM\n",
    "        self.bangla_lstm = list(bangla_model.children())[-2]  # LSTM layer\n",
    "        self.english_feature_extractor = nn.Sequential(*list(english_model.children())[:-2])  # Up to LSTM\n",
    "        self.english_lstm = list(english_model.children())[-2]  # LSTM layer\n",
    "        \n",
    "        # Joint layers\n",
    "        self.fc1 = nn.Linear(512, 32)\n",
    "        self.fc2 = nn.Linear(32, combined_classes)\n",
    "\n",
    "    def forward(self, bangla_x, english_x):\n",
    "        # Bangla feature extraction\n",
    "        bangla_features = self.bangla_feature_extractor(bangla_x)  # 4D output\n",
    "        bangla_features = bangla_features.permute(0, 2, 3, 1).reshape(bangla_features.size(0), -1, 1024)\n",
    "        bangla_features, _ = self.bangla_lstm(bangla_features)  # LSTM processing\n",
    "        \n",
    "        # English feature extraction\n",
    "        english_features = self.english_feature_extractor(english_x)  # 4D output\n",
    "        english_features = english_features.permute(0, 2, 3, 1).reshape(english_features.size(0), -1, 1024)\n",
    "        english_features, _ = self.english_lstm(english_features)  # LSTM processing\n",
    "\n",
    "        # Concatenate features\n",
    "        combined_features = torch.cat((bangla_features[:, -1, :], english_features[:, -1, :]), dim=1)\n",
    "\n",
    "        # Fully connected layers\n",
    "        x = torch.relu(self.fc1(combined_features))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class CombinedDataset(Dataset):\n",
    "    def __init__(self, bangla_loader, english_loader):\n",
    "        self.bangla_data = list(bangla_loader.dataset)\n",
    "        self.english_data = list(english_loader.dataset)\n",
    "\n",
    "        # Match lengths\n",
    "        min_length = min(len(self.bangla_data), len(self.english_data))\n",
    "        self.bangla_data = self.bangla_data[:min_length]\n",
    "        self.english_data = self.english_data[:min_length]\n",
    "\n",
    "        # Unique combined labels\n",
    "        self.combined_labels = set(\n",
    "            hash((f'b{self.bangla_data[idx][1]}', f'e{self.english_data[idx][1]}'))\n",
    "            for idx in range(len(self.bangla_data))\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.bangla_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        bangla_image, bangla_label = self.bangla_data[idx]\n",
    "        english_image, english_label = self.english_data[idx]\n",
    "\n",
    "        # Unique label\n",
    "        combined_label = hash((f'b{bangla_label}', f'e{english_label}')) % len(self.combined_labels)\n",
    "        return bangla_image, english_image, combined_label\n",
    "\n",
    "    @property\n",
    "    def num_classes(self):\n",
    "        return len(self.combined_labels)\n",
    "\n",
    "# Create combined dataset and dataloader\n",
    "combined_dataset = CombinedDataset(bangla_train_loader, english_train_loader)\n",
    "combined_dataloader = DataLoader(combined_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Initialize combined model\n",
    "combined_classes = combined_dataset.num_classes\n",
    "combined_model = CombinedModel(bangla_model, english_model, combined_classes)\n",
    "\n",
    "# Unfreeze all parameters in the combined model\n",
    "for param in combined_model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Define the optimizer to update all layers\n",
    "optimizer = optim.Adam(combined_model.parameters(), lr=0.0001)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training Function\n",
    "def train_combined_model(model, train_loader, val_loader, criterion, optimizer, epochs=10):\n",
    "    history = {\n",
    "        \"train_loss\": [],\n",
    "        \"train_accuracy\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"val_accuracy\": []\n",
    "    }\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        for bangla_images, english_images, labels in train_loader:\n",
    "            bangla_images, english_images, labels = bangla_images.cuda(), english_images.cuda(), labels.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(bangla_images, english_images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct_train += (preds == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_accuracy = 100 * correct_train / total_train\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for bangla_images, english_images, labels in val_loader:\n",
    "                bangla_images, english_images, labels = bangla_images.cuda(), english_images.cuda(), labels.cuda()\n",
    "                outputs = model(bangla_images, english_images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                correct_val += (preds == labels).sum().item()\n",
    "                total_val += labels.size(0)\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_accuracy = 100 * correct_val / total_val\n",
    "\n",
    "        # Update history\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_accuracy\"].append(train_accuracy)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_accuracy\"].append(val_accuracy)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}: \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "combined_model = combined_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1798\n"
     ]
    }
   ],
   "source": [
    "print(combined_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1123771/1808910720.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  combined_model.load_state_dict(torch.load(\"bilingual_ocr_combined_model_fully_trained.pth\"))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for CombinedModel:\n\tsize mismatch for fc2.weight: copying a param with shape torch.Size([1797, 32]) from checkpoint, the shape in current model is torch.Size([1798, 32]).\n\tsize mismatch for fc2.bias: copying a param with shape torch.Size([1797]) from checkpoint, the shape in current model is torch.Size([1798]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcombined_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbilingual_ocr_combined_model_fully_trained.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/course/CV/project/OCR/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:2584\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2576\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2577\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2578\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2579\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[1;32m   2580\u001b[0m             ),\n\u001b[1;32m   2581\u001b[0m         )\n\u001b[1;32m   2583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2584\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2585\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2586\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[1;32m   2587\u001b[0m         )\n\u001b[1;32m   2588\u001b[0m     )\n\u001b[1;32m   2589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for CombinedModel:\n\tsize mismatch for fc2.weight: copying a param with shape torch.Size([1797, 32]) from checkpoint, the shape in current model is torch.Size([1798, 32]).\n\tsize mismatch for fc2.bias: copying a param with shape torch.Size([1797]) from checkpoint, the shape in current model is torch.Size([1798])."
     ]
    }
   ],
   "source": [
    "combined_model.load_state_dict(torch.load(\"bilingual_ocr_combined_model_fully_trained.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Directory: Dataset/Bangla/Dataset/Train\n",
      "Checked 12000 images in total.\n",
      "Removed 0 unreadable images.\n",
      "Removed 0 non-image files.\n",
      "Total number of images: 12000\n",
      "Total number of labels: 50\n",
      "\n",
      "Directory: Dataset/Bangla/Dataset/Test\n",
      "Checked 3000 images in total.\n",
      "Removed 0 unreadable images.\n",
      "Removed 0 non-image files.\n",
      "Total number of images: 3000\n",
      "Total number of labels: 50\n",
      "\n",
      "Directory: Dataset/English/data/training_data\n",
      "Checked 20628 images in total.\n",
      "Removed 0 unreadable images.\n",
      "Removed 0 non-image files.\n",
      "Total number of images: 20628\n",
      "Total number of labels: 36\n",
      "\n",
      "Directory: Dataset/English/data/testing_data\n",
      "Checked 1008 images in total.\n",
      "Removed 0 unreadable images.\n",
      "Removed 0 non-image files.\n",
      "Total number of images: 1008\n",
      "Total number of labels: 36\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from preprocess import preprocess_image  # Import from preprocess.py\n",
    "from model import OCRModel  # Import from separate.py\n",
    "from dataload import bangla_load, english_load\n",
    "\n",
    "# Load Bangla and English data loaders\n",
    "bangla_train_loader, bangla_val_loader, bangla_test_loader, bangla_num_classes = bangla_load\n",
    "english_train_loader, english_val_loader, english_test_loader, english_num_classes = english_load\n",
    "\n",
    "# Load pre-trained models with weights_only=True\n",
    "bangla_model = OCRModel(bangla_num_classes)\n",
    "english_model = OCRModel(english_num_classes)\n",
    "bangla_model.load_state_dict(torch.load(\"saved_models/bangla_model.pth\", weights_only=True)['model_state_dict'])\n",
    "english_model.load_state_dict(torch.load(\"saved_models/english_model.pth\", weights_only=True)['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined model\n",
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, bangla_model, english_model, combined_classes):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        self.bangla_feature_extractor = nn.Sequential(*list(bangla_model.children())[:-2])  # Up to LSTM\n",
    "        self.bangla_lstm = list(bangla_model.children())[-2]  # LSTM layer\n",
    "        self.english_feature_extractor = nn.Sequential(*list(english_model.children())[:-2])  # Up to LSTM\n",
    "        self.english_lstm = list(english_model.children())[-2]  # LSTM layer\n",
    "        \n",
    "        # Joint layers\n",
    "        self.fc1 = nn.Linear(512, 32)\n",
    "        self.fc2 = nn.Linear(32, combined_classes)\n",
    "\n",
    "    def forward(self, bangla_x, english_x):\n",
    "        # Bangla feature extraction\n",
    "        bangla_features = self.bangla_feature_extractor(bangla_x)  # 4D output\n",
    "        bangla_features = bangla_features.permute(0, 2, 3, 1).reshape(bangla_features.size(0), -1, 1024)\n",
    "        bangla_features, _ = self.bangla_lstm(bangla_features)  # LSTM processing\n",
    "        \n",
    "        # English feature extraction\n",
    "        english_features = self.english_feature_extractor(english_x)  # 4D output\n",
    "        english_features = english_features.permute(0, 2, 3, 1).reshape(english_features.size(0), -1, 1024)\n",
    "        english_features, _ = self.english_lstm(english_features)  # LSTM processing\n",
    "\n",
    "        # Concatenate features\n",
    "        combined_features = torch.cat((bangla_features[:, -1, :], english_features[:, -1, :]), dim=1)\n",
    "\n",
    "        # Fully connected layers\n",
    "        x = torch.relu(self.fc1(combined_features))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class CombinedDataset(Dataset):\n",
    "    def __init__(self, bangla_loader, english_loader):\n",
    "        self.bangla_data = list(bangla_loader.dataset)\n",
    "        self.english_data = list(english_loader.dataset)\n",
    "\n",
    "        # Match lengths\n",
    "        min_length = min(len(self.bangla_data), len(self.english_data))\n",
    "        self.bangla_data = self.bangla_data[:min_length]\n",
    "        self.english_data = self.english_data[:min_length]\n",
    "\n",
    "        # Unique combined labels\n",
    "        self.combined_labels = set(\n",
    "            hash((f'b{self.bangla_data[idx][1]}', f'e{self.english_data[idx][1]}'))\n",
    "            for idx in range(len(self.bangla_data))\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.bangla_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        bangla_image, bangla_label = self.bangla_data[idx]\n",
    "        english_image, english_label = self.english_data[idx]\n",
    "\n",
    "        # Unique label\n",
    "        combined_label = hash((f'b{bangla_label}', f'e{english_label}')) % len(self.combined_labels)\n",
    "        return bangla_image, english_image, combined_label\n",
    "\n",
    "    @property\n",
    "    def num_classes(self):\n",
    "        return len(self.combined_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1122997/207664137.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  combined_model.load_state_dict(torch.load(\"bilingual_ocr_combined_model_fully_trained.pth\"))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for CombinedModel:\n\tsize mismatch for fc2.weight: copying a param with shape torch.Size([1797, 32]) from checkpoint, the shape in current model is torch.Size([1798, 32]).\n\tsize mismatch for fc2.bias: copying a param with shape torch.Size([1797]) from checkpoint, the shape in current model is torch.Size([1798]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m combined_classes \u001b[38;5;241m=\u001b[39m combined_dataset\u001b[38;5;241m.\u001b[39mnum_classes\n\u001b[1;32m      7\u001b[0m combined_model \u001b[38;5;241m=\u001b[39m CombinedModel(bangla_model, english_model, combined_classes)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mcombined_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbilingual_ocr_combined_model_fully_trained.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/course/CV/project/OCR/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:2584\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2576\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2577\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2578\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2579\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[1;32m   2580\u001b[0m             ),\n\u001b[1;32m   2581\u001b[0m         )\n\u001b[1;32m   2583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2584\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2585\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2586\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[1;32m   2587\u001b[0m         )\n\u001b[1;32m   2588\u001b[0m     )\n\u001b[1;32m   2589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for CombinedModel:\n\tsize mismatch for fc2.weight: copying a param with shape torch.Size([1797, 32]) from checkpoint, the shape in current model is torch.Size([1798, 32]).\n\tsize mismatch for fc2.bias: copying a param with shape torch.Size([1797]) from checkpoint, the shape in current model is torch.Size([1798])."
     ]
    }
   ],
   "source": [
    "# Create combined dataset and dataloader\n",
    "combined_dataset = CombinedDataset(bangla_train_loader, english_train_loader)\n",
    "combined_dataloader = DataLoader(combined_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Initialize combined model\n",
    "combined_classes = combined_dataset.num_classes\n",
    "combined_model = CombinedModel(bangla_model, english_model, combined_classes)\n",
    "combined_model.load_state_dict(torch.load(\"bilingual_ocr_combined_model_fully_trained.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create combined test dataset and dataloader\n",
    "combined_test_dataset = CombinedDataset(bangla_test_loader, english_test_loader)\n",
    "combined_test_dataloader = DataLoader(combined_test_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "\n",
    "class Evaluator:\n",
    "    def __init__(self, model, test_loader, num_classes, output_dir=\"evaluation_outputs\"):\n",
    "        \"\"\"\n",
    "        Initializes the evaluator.\n",
    "\n",
    "        Args:\n",
    "            model (torch.nn.Module): Trained model to evaluate.\n",
    "            test_loader (DataLoader): DataLoader for the test dataset.\n",
    "            num_classes (int): Number of classes in the dataset.\n",
    "            output_dir (str): Directory to save evaluation plots and metrics.\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.test_loader = test_loader\n",
    "        self.num_classes = num_classes\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.output_dir = output_dir\n",
    "\n",
    "        # Create output directory if it doesn't exist\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    def evaluate_and_save(self):\n",
    "        \"\"\"\n",
    "        Evaluates the model on test data and saves visualizations and metrics to disk.\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        all_images = []\n",
    "        all_labels = []\n",
    "        all_predictions = []\n",
    "        all_probabilities = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in self.test_loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                outputs = self.model(images)\n",
    "                probabilities = torch.softmax(outputs, dim=1)\n",
    "                _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "                # Collect all images, labels, and predictions\n",
    "                all_images.extend(images.cpu())  # Collect all test images\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_predictions.extend(predictions.cpu().numpy())\n",
    "                all_probabilities.extend(probabilities.cpu().numpy())\n",
    "\n",
    "        # Convert collected data to NumPy arrays\n",
    "        all_labels = np.array(all_labels)\n",
    "        all_predictions = np.array(all_predictions)\n",
    "        all_probabilities = np.array(all_probabilities)\n",
    "\n",
    "        # Save sample predictions\n",
    "        self._save_sample_predictions(all_images, all_labels, all_predictions)\n",
    "\n",
    "        # Save confusion matrix\n",
    "        self._save_confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "        # Save classification report\n",
    "        self._save_classification_report(all_labels, all_predictions)\n",
    "\n",
    "        # Save ROC curve\n",
    "        self._save_roc_curve(all_labels, all_probabilities)\n",
    "\n",
    "    def _save_sample_predictions(self, images, labels, predictions):\n",
    "        \"\"\"\n",
    "        Randomly selects test images until there are images of 5 unique labels \n",
    "        and saves them along with their predictions and true labels to a file.\n",
    "        \"\"\"\n",
    "        max_samples = 5  # Limit the number of unique labels\n",
    "        unique_labels = {}\n",
    "        selected_indices = []\n",
    "        total_samples = len(labels)\n",
    "\n",
    "        # Randomly shuffle indices\n",
    "        indices = list(range(total_samples))\n",
    "        random.shuffle(indices)\n",
    "\n",
    "        # Select images with unique labels\n",
    "        for idx in indices:\n",
    "            label = labels[idx]\n",
    "            if label not in unique_labels:\n",
    "                unique_labels[label] = True\n",
    "                selected_indices.append(idx)\n",
    "                if len(unique_labels) == max_samples:\n",
    "                    break\n",
    "\n",
    "        # Plot and save the selected samples\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        for i, idx in enumerate(selected_indices):\n",
    "            plt.subplot(1, len(selected_indices), i + 1)\n",
    "            plt.imshow(images[idx].squeeze(), cmap='gray')\n",
    "            plt.title(f\"True: {labels[idx]}\\nPred: {predictions[idx]}\")\n",
    "            plt.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        file_path = os.path.join(self.output_dir, \"sample_predictions.png\")\n",
    "        plt.savefig(file_path)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def _save_confusion_matrix(self, labels, predictions):\n",
    "        \"\"\"\n",
    "        Saves the confusion matrix to a file.\n",
    "        \"\"\"\n",
    "        cm = confusion_matrix(labels, predictions)\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=True, yticklabels=True)\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        file_path = os.path.join(self.output_dir, \"confusion_matrix.png\")\n",
    "        plt.savefig(file_path)\n",
    "        plt.close()\n",
    "\n",
    "    def _save_classification_report(self, labels, predictions):\n",
    "        \"\"\"\n",
    "        Saves the classification report to a text file.\n",
    "        \"\"\"\n",
    "        report = classification_report(labels, predictions)\n",
    "        file_path = os.path.join(self.output_dir, \"classification_report.txt\")\n",
    "        with open(file_path, \"w\") as f:\n",
    "            f.write(report)\n",
    "\n",
    "    def _save_roc_curve(self, labels, probabilities):\n",
    "        # Binarize labels for multi-class ROC calculation\n",
    "        labels_binarized = label_binarize(labels, classes=range(self.num_classes))\n",
    "        fpr, tpr, _ = roc_curve(labels_binarized.ravel(), probabilities.ravel())\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        # Plot the ROC curve\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.plot(fpr, tpr, label=f\"Combined Classes (AUC = {roc_auc:.2f})\")\n",
    "        plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line\n",
    "        plt.title(\"ROC Curve (All Classes)\")\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        file_path = os.path.join(self.output_dir, \"roc_curve.png\")\n",
    "        plt.savefig(file_path)\n",
    "        plt.close()\n",
    "\n",
    "print(bangla_test_loader)\n",
    "evaluator = Evaluator(combined_model, combined_test_dataloader, combined_classes, output_dir=\"evaluation_outputs\")\n",
    "evaluator.evaluate_and_save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
